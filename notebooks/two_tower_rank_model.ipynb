{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wogsim/two_tower_recmodel/blob/main/notebooks/two_tower_rank_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb271239",
      "metadata": {
        "id": "eb271239"
      },
      "source": [
        "\n",
        "\n",
        "# Рекомендации на основе Трансформера\n",
        "\n",
        "Этот проект — это система рекомендаций, использующая архитектуру **Трансформер** для анализа истории позитивных действий пользователя.\n",
        "\n",
        "**Цель:** Научить модель эффективно ранжировать товары, которые пользователь, скорее всего, добавит в корзину.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Входные данные (История взаимодействий)\n",
        "\n",
        "Мы будем использовать историю **положительных взаимодействий** пользователя (сессии):\n",
        "* **Клики**\n",
        "* **Добавления в корзину**\n",
        "* **Покупки**\n",
        "\n",
        "(Примечание: Просмотры временно **игнорируются** для упрощения, но могут быть добавлены позже.)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Двухэтапное Обучение\n",
        "\n",
        "Обучение модели будет состоять из двух фаз: **Pretrain** (Предварительное обучение) и **Finetune** (Тонкая настройка).\n",
        "\n",
        "### А. Pretrain (Предварительное обучение)\n",
        "\n",
        "* **Задача:** Обучить модель решать **общую задачу**, максимально утилизируя **все имеющиеся данные** (клики, корзины, покупки).\n",
        "* **Результат:** Получение сильных общих представлений (эмбеддингов) для пользователей и товаров.\n",
        "* **Свойство:** Хорошо масштабируется — добавление данных повышает качество.\n",
        "\n",
        "### Б. Finetune (Тонкая настройка)\n",
        "\n",
        "* **Задача:** **Адаптировать** модель под **конкретную целевую задачу ранжирования** на тесте.\n",
        "* **Целевая Метрика:** **$ndcg@10$** (Normalized Discounted Cumulative Gain на 10) по группам (`request_id`).\n",
        "* **Метод:** Обучение на **попарную функцию потерь** (Pairwise Loss) — будем использовать **Calibrated Pairwise Logistic** (подробности ниже).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Целевая Задача Finetune (Ранжирование)\n",
        "\n",
        "На этапе Finetune мы фокусируемся на ранжировании внутри групп (`request_id`).\n",
        "\n",
        "* **Метки:**\n",
        "    * **1 (Позитивный):** Товар был **добавлен в корзину**.\n",
        "    * **0 (Негативный):** Товар был **просмотрен** (но не добавлен в корзину).\n",
        "* **Исключения:** Клики и покупки **не** учитываются, так как их нет в итоговом тестовом наборе.\n",
        "* **Цель:** **Отранжировать** единички (корзины) как можно **выше** ноликов (просмотров)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8affb83",
      "metadata": {
        "id": "e8affb83"
      },
      "source": [
        "### Pretrain:\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/8GksnWD/Screenshot-2025-05-04-at-10-15-36.png\" width=\"500\" alt=\"pretrain\">\n",
        "</div>\n",
        "\n",
        "Предварительное обучение состоит из двух взаимодополняющих задач: **Next-Positive Prediction (NPP)** и **Feedback Prediction (FP)**.\n",
        "\n",
        "### Общая структура токена\n",
        "\n",
        "Каждое положительное взаимодействие ($t$) кодируется как **токен**, который является суммой векторов трёх характеристик:\n",
        "$$\\text{Токен}_t = \\mathbf{c}_t + \\mathbf{i}_t + \\mathbf{f}_t$$\n",
        "* $\\mathbf{i}_t$ — **Товар** (Item) взаимодействия.\n",
        "* $\\mathbf{c}_t$ — **Контекст** (Context) взаимодействия.\n",
        "* $\\mathbf{f}_t$ — **Фидбек** (Feedback): клик, корзина или покупка.\n",
        "\n",
        "### Next-Positive Prediction ($\\mathcal{L}_{\\mathrm{NPP}}$)\n",
        "* **Задача:** Предсказать вероятность следующего товара $i_t$, используя Softmax и косинусное сходство:\n",
        "$$\n",
        "P(\\text{item}=i_t\\mid \\text{history}=S_{t-1},\\;\\text{context}=c_t)\\,.\n",
        "$$\n",
        "* **Позднее связывание (Next-Positive):** Трансформер выдает $h_{t-1}$. Для предсказания используем:\n",
        "$$\n",
        "\\hat h^c_t = \\mathrm{MLP}\\bigl(\\mathrm{Concat}(h_{t-1},\\mathbf{c}_t)\\bigr).\n",
        "$$\n",
        "\n",
        "### Feedback Prediction ($\\mathcal{L}_{\\mathrm{FP}}$)\n",
        "* **Задача:** Предсказать вероятность типа фидбека $f_t$ (классификация на три класса: клик, корзина, покупка):\n",
        "$$\n",
        "P(\\text{feedback}=f_t\\mid \\text{history}=S_{t-1},\\;\\text{context}=c_t,\\;\\text{item}=i_t).\n",
        "$$\n",
        "* **Позднее связывание (Feedback):** Используем $h_{t-1}$, $\\mathbf{c}_t$ и $\\mathbf{i}_t$:\n",
        "$$\n",
        "\\hat h^i_t = \\mathrm{MLP}\\bigl(\\mathrm{Concat}(h_{t-1},\\mathbf{c}_t,\\mathbf{i}_t)\\bigr).\n",
        "$$\n",
        "\n",
        "### Итоговый Pretrain Loss\n",
        "\n",
        "$$\\mathcal{L}_{\\rm pre\\text{-}train} = \\mathcal{L}_{\\mathrm{NPP}} + \\mathcal{L}_{\\mathrm{FP}}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67330ec3",
      "metadata": {
        "id": "67330ec3"
      },
      "source": [
        "### Finetune\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/kgwt7pRb/Screenshot-2025-05-04-at-10-15-48.png\" width=\"500\" alt=\"finetune\">\n",
        "</p>\n",
        "\n",
        "\n",
        "#### Постановка задачи\n",
        "\n",
        "Пусть для пользователя с идентификатором `user_id` есть сформированная история взаимодействий и набор групп товаров, каждая из которых имеет свой `request_id`.\n",
        "\n",
        "* **Скрытые состояния:**\n",
        "    $$h_0, h_1, \\dots, h_t$$\n",
        "* **Группа (`request_id`):** Множество товаров, каждый из которых имеет бинарную метку:\n",
        "    * **1:** Товар был добавлен в корзину (позитив).\n",
        "    * **0:** Товар был просмотрен (негатив).\n",
        "\n",
        "**Цель:** Для каждого товара внутри группы оценить его **релевантность** пользователю, используя актуальное скрытое состояние пользователя.\n",
        "\n",
        "---\n",
        "\n",
        "#### Учет временной задержки (Consistency with Validation)\n",
        "\n",
        "На валидации и тесте между последним известным состоянием истории и моментом показа новой группы может быть значительный разрыв (от 2 дней до 1 месяца). Чтобы имитировать это и обеспечить консистентность, мы добавляем задержку в процесс обучения:\n",
        "\n",
        "1.  **Выбор задержки:** Для каждой группы случайно выбирается задержка $\\Delta$:\n",
        "$$\\Delta \\sim \\mathrm{Uniform}(2\\ \\text{дн.},\\ 32 \\text{дн.}).$$\n",
        "2.  **Выбор состояния:** Находим самое *позднее* скрытое состояние $h_k$, которое предшествует текущей группе *не менее* чем на $\\Delta$.\n",
        "3.  **Вектор пользователя:** Используем это состояние **$h_k$** как итоговый вектор пользователя для расчета потерь в данной группе.\n",
        "\n",
        "---\n",
        "\n",
        "#### Попарная ранжирующая функция потерь\n",
        "\n",
        "Мы обучаем модель ранжировать позитивные товары выше негативных в рамках одной группы.\n",
        "\n",
        "1.  **Формирование пар:** Внутри каждой группы (`request_id`) генерируем все возможные пары товаров $(i, j)$, где:\n",
        "    * Товар $i$ имеет метку **1** (корзина, позитив).\n",
        "    * Товар $j$ имеет метку **0** (просмотр, негатив).\n",
        "2.  **Расчет потерь:** Для каждой такой пары рассчитываем ранжирующую функцию потерь (например, **Calibrated Pairwise Logistic**), используя предсказанные релевантности для товаров $i$ и $j$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690d22b4",
      "metadata": {
        "id": "690d22b4"
      },
      "source": [
        "## 2. Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IxE0DgCs0CoG",
      "metadata": {
        "id": "IxE0DgCs0CoG"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/wogsim/two_tower_recmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tPiUHHE50Kem",
      "metadata": {
        "collapsed": true,
        "id": "tPiUHHE50Kem"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/two_tower_recmodel/notebooks/requirements.txt\n",
        "!pip install -e two_tower_recmodel/grocery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7lUF4pHB0Jxq",
      "metadata": {
        "id": "7lUF4pHB0Jxq"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/recsys_course/data/lavka\"\n",
        "\n",
        "from grocery.utils.dataset import download_and_extract\n",
        "download_and_extract(\n",
        "     url=\"https://www.kaggle.com/api/v1/datasets/download/thekabeton/ysda-recsys-2025-lavka-dataset\",\n",
        "     filename=\"lavka.zip\",\n",
        "    dest_dir=DATA_DIR\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RYxiGoUZ2PT6",
      "metadata": {
        "id": "RYxiGoUZ2PT6"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/recsys_course/data/lavka\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a60653f7",
      "metadata": {
        "id": "a60653f7"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "from collections import deque\n",
        "from typing import Dict, Any, Generator, Iterable, Optional\n",
        "from abc import ABC, abstractmethod\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "614d9df1",
      "metadata": {
        "id": "614d9df1"
      },
      "source": [
        " Оставляем только небольшой поднабор всех признаков. Остальные признаки буду учтены в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f704462",
      "metadata": {
        "id": "7f704462"
      },
      "outputs": [],
      "source": [
        "train_df = pl.read_parquet(DATA_DIR + '/train.parquet').select(['action_type', 'product_id', 'source_type', 'timestamp', 'user_id', 'request_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8987a472",
      "metadata": {
        "id": "8987a472"
      },
      "source": [
        "### Разделение на трейн и валидация:\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/yBPn87t7/IMG000-19.jpg\" width=\"500\" alt=\"split\">\n",
        "</div>\n",
        "\n",
        "Для оценки модели будем использовать train данные. Из них сформируем валидационную и обучающую части. Для того, чтобы получить корректные метрики на валидации, важно повторить все особенности тестовых данных:\n",
        "- 2 дня разница между train и valid\n",
        "- 1 месяц на valid\n",
        "- оставляем только просмотр и корзину\n",
        "- группы с >= 10 товарами\n",
        "- группы с хотя бы одной корзиной и хотя бы одним просмотром"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde01cf5",
      "metadata": {
        "id": "cde01cf5"
      },
      "outputs": [],
      "source": [
        "class ActionType:\n",
        "    VIEW = 'AT_View'\n",
        "    CLICK = 'AT_Click'\n",
        "    CART_UPDATE = 'AT_CartUpdate'\n",
        "    PURCHASE = 'AT_Purchase'\n",
        "\n",
        "\n",
        "class Preprocessor:\n",
        "    mapping_action_types = {\n",
        "        ActionType.VIEW: 0,\n",
        "        ActionType.CART_UPDATE: 1,\n",
        "        ActionType.CLICK: 2,\n",
        "        ActionType.PURCHASE: 3\n",
        "    }\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_df: pl.DataFrame,\n",
        "    ):\n",
        "        self.train_df = train_df\n",
        "\n",
        "    def _map_col(self, column: str, cast: pl.DataType = None) -> dict:\n",
        "        uniques = sorted(self.train_df.select(pl.col(column)).unique().to_series().to_list())\n",
        "        mapping = {val: idx for idx, val in enumerate(uniques)}\n",
        "\n",
        "        for attr in (\"train_df\",):\n",
        "            df = getattr(self, attr)\n",
        "            df = df.with_columns(\n",
        "                pl.col(column)\n",
        "                .replace(mapping)\n",
        "                .alias(column)\n",
        "            )\n",
        "            if cast is not None:\n",
        "                df = df.with_columns(pl.col(column).cast(cast))\n",
        "            setattr(self, attr, df)\n",
        "\n",
        "        return mapping\n",
        "\n",
        "    def run(self):\n",
        "        self.train_df = self.train_df.with_columns(\n",
        "            pl.col(\"source_type\").fill_null(\"\").alias(\"source_type\")\n",
        "        )\n",
        "\n",
        "        self.mapping_product_ids = self._map_col(\"product_id\")\n",
        "        self.mapping_user_ids = self._map_col(\"user_id\")\n",
        "        self.mapping_source_types = self._map_col(\"source_type\", cast=pl.Int8)\n",
        "\n",
        "        self.train_df = self.train_df.with_columns(\n",
        "            pl.col(\"action_type\")\n",
        "            .replace(self.mapping_action_types)\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"action_type\")\n",
        "        )\n",
        "\n",
        "        self.targets = (\n",
        "            self.train_df\n",
        "            .filter(\n",
        "                pl.col(\"request_id\").is_not_null() &\n",
        "                pl.col(\"action_type\").is_in([0, 1]) &\n",
        "                (pl.col(\"source_type\") != self.mapping_source_types[\"ST_Catalog\"])\n",
        "            )\n",
        "            .group_by([\n",
        "                \"user_id\",\n",
        "                \"request_id\",\n",
        "                \"product_id\",\n",
        "            ])\n",
        "            .agg([\n",
        "                pl.col(\"action_type\").max(),\n",
        "                pl.col(\"timestamp\").min(),\n",
        "                pl.col(\"source_type\").mode().first()\n",
        "            ])\n",
        "        )\n",
        "\n",
        "        requests_with_cartupdate_and_view = (\n",
        "            self.targets\n",
        "            .select([\"request_id\", \"action_type\", \"timestamp\"])\n",
        "            .group_by(\"request_id\")\n",
        "            .agg([\n",
        "                pl.col(\"action_type\").max().alias(\"max_t\"),\n",
        "                pl.col(\"action_type\").min().alias(\"min_t\"),\n",
        "                pl.len(),\n",
        "                pl.col(\"timestamp\").min().alias(\"req_ts\")\n",
        "            ])\n",
        "            .with_columns(sum_targets=pl.col('max_t').add(pl.col('min_t')))\n",
        "            .filter(pl.col('sum_targets') == 1)\n",
        "            .filter(pl.col('len') >= 10)\n",
        "            .select([\"request_id\", \"req_ts\"])\n",
        "        )\n",
        "        self.targets = (\n",
        "            self.targets\n",
        "            .drop(\"timestamp\")\n",
        "            .join(requests_with_cartupdate_and_view, on=\"request_id\", how=\"inner\")\n",
        "            .with_columns(pl.col(\"req_ts\").alias(\"timestamp\"))\n",
        "            .drop(\"req_ts\")\n",
        "        )\n",
        "        self.targets = (\n",
        "            self.targets\n",
        "            .group_by(['user_id', 'request_id', 'timestamp', 'source_type'])\n",
        "            .agg([\n",
        "                pl.col('product_id'),\n",
        "                pl.col('action_type'),\n",
        "            ])\n",
        "        )\n",
        "\n",
        "        self.timesplit_valid_end = self.train_df[\"timestamp\"].max()\n",
        "        self.timesplit_valid_start = self.timesplit_valid_end - 30 * 24 * 60 * 60\n",
        "        self.timesplit_train_end = self.timesplit_valid_start - 2 * 24 * 60 * 60\n",
        "        self.timesplit_train_start = self.train_df[\"timestamp\"].min()\n",
        "\n",
        "        self.train_df = (\n",
        "            self.train_df\n",
        "            .filter(pl.col(\"action_type\") != 0)\n",
        "            .drop(\"request_id\")\n",
        "        )\n",
        "\n",
        "        self.train_targets = self.targets.filter(\n",
        "            pl.col(\"timestamp\") <= self.timesplit_train_end\n",
        "        )\n",
        "        self.valid_targets = self.targets.filter(\n",
        "            (pl.col(\"timestamp\") > self.timesplit_valid_start) &\n",
        "            (pl.col(\"timestamp\") <= self.timesplit_valid_end)\n",
        "        )\n",
        "        self.train_history = self.train_df.filter(pl.col('timestamp') <= self.timesplit_train_end)\n",
        "        self.valid_history = self.train_df.filter(pl.col('timestamp') > self.timesplit_train_end)\n",
        "\n",
        "        return (\n",
        "            self.train_history,\n",
        "            self.valid_history,\n",
        "            self.train_targets,\n",
        "            self.valid_targets\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3347dba2",
      "metadata": {
        "id": "3347dba2"
      },
      "outputs": [],
      "source": [
        "preprocessor = Preprocessor(train_df)\n",
        "train_history, valid_history, train_targets, valid_targets = preprocessor.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd7ada58",
      "metadata": {
        "id": "bd7ada58"
      },
      "source": [
        "- train_history/valid_history - позитивные взаимодействия пользователей\n",
        "- train_targets/valid_targets - группы для finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5773f69f",
      "metadata": {
        "id": "5773f69f"
      },
      "source": [
        "## 3. Подготовка данных для pretrain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c44cca",
      "metadata": {
        "id": "b2c44cca"
      },
      "source": [
        "Для pretrain и finetune работа происходит с двумя последовательностями: последовательностью позитивных взаимодействий и последовательностью request-ов пользователя. Далее будем называть их history и candidates. На pretrain нам будет нужна только history.\n",
        "\n",
        "#### Обрезание историй\n",
        "\n",
        "У пользователей может быть разное количество позитивных событий в истории. Для простоты будет рассматривать последние 512 событий. Если вдруг их будет больше, то будем обрезать.\n",
        "\n",
        "#### Схемы таблиц и пример\n",
        "\n",
        "Схема для history имеет вид:\n",
        "```python\n",
        "HISTORY_SCHEMA = pl.Struct([{\n",
        "    'source_type': pl.List(pl.Int64),\n",
        "    'action_type': pl.List(pl.Int64),\n",
        "    'product_id': pl.List(pl.Int64),\n",
        "    'position': pl.List(pl.Int64),\n",
        "    'targets_inds': pl.List(pl.Int64),\n",
        "    'targets_lengths': pl.List(pl.Int64), # количество таргет событий в истории\n",
        "    'lengths': pl.List(pl.Int64), # длина всей истории\n",
        "}]).\n",
        "```\n",
        "`position` это индексы событий в истории (нужно будут далее для позиционных эмбеддингов), `targets_inds` - индексы тех позиций, которые будут участвовать в подсчете функции потерь. Они нужны, чтобы разделять потерю по событиям из обучающий и валидационной частей. `targets_lengths` - количество таких событий в истории.\n",
        "Пример: Пусть есть некоторый пользователь с историей из позитивных взаимодействий длины 5. Пусть первые 3 события попадают в обучение, а последние 2 в валидацию. Тогда:\n",
        "```python\n",
        "history_train_sample = pl.DataFrame([{\n",
        "    'source_type': [1, 1, 2, 3, 4],\n",
        "    'action_type': [1, 0, 1, 0, 1],\n",
        "    'product_id': [1, 2, 3, 4, 5],\n",
        "    'position': [0, 1, 2, 3, 4],\n",
        "    'targets_inds': [0, 1, 2],\n",
        "    'targets_lengths': [3],\n",
        "    'lengths': [5]\n",
        "}])\n",
        "history_valid_sample = pl.DataFrame([{\n",
        "    'source_type': [1, 1, 2, 3, 4],\n",
        "    'action_type': [1, 0, 1, 0, 1],\n",
        "    'product_id': [1, 2, 3, 4, 5],\n",
        "    'position': [0, 1, 2, 3, 4],\n",
        "    'targets_inds': [3, 4],\n",
        "    'targets_lengths': [2],\n",
        "    'lengths': [5]\n",
        "}])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6b6709",
      "metadata": {
        "id": "0d6b6709"
      },
      "outputs": [],
      "source": [
        "def ensure_sorted_by_timestamp(group: Iterable[Dict[str, Any]]) -> Generator[Dict[str, Any], None, None]:\n",
        "    \"\"\"\n",
        "    Ensures that the given iterable of events is sorted by the 'timestamp' field.\n",
        "\n",
        "    This function iterates over each event in the provided iterable and checks if the\n",
        "    'timestamp' of the current event is greater than or equal to the 'timestamp' of the\n",
        "    previous event. If any event has a 'timestamp' that is less than the previous event's\n",
        "    'timestamp', an AssertionError is raised.\n",
        "\n",
        "    @param group: An iterable of dictionaries, where each dictionary represents an event with at least a 'timestamp' key.\n",
        "    @return: A generator yielding each event from the input iterable in order, ensuring they are sorted by 'timestamp'.\n",
        "    @raises AssertionError: If the events are not sorted by 'timestamp'.\n",
        "    \"\"\"\n",
        "\n",
        "    events = chain(group)\n",
        "\n",
        "    prev_timestamp = 0\n",
        "    for event in events:\n",
        "        if event[\"timestamp\"] >= prev_timestamp:\n",
        "            prev_timestamp = event[\"timestamp\"]\n",
        "            yield event\n",
        "        else:\n",
        "            raise AssertionError(\"Events are not sorted by timestamp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6949bd9a",
      "metadata": {
        "id": "6949bd9a"
      },
      "outputs": [],
      "source": [
        "class Mapper(ABC):\n",
        "    HISTORY_SCHEMA = pl.Struct({\n",
        "        'source_type': pl.List(pl.Int64),\n",
        "        'action_type': pl.List(pl.Int64),\n",
        "        'product_id': pl.List(pl.Int64),\n",
        "        'position': pl.List(pl.Int64),\n",
        "        'targets_inds': pl.List(pl.Int64),\n",
        "        'targets_lengths': pl.List(pl.Int64), # количество таргет событий в истории\n",
        "        'lengths': pl.List(pl.Int64), # длина всей истории\n",
        "    })\n",
        "    CANDIDATES_SCHEMA = pl.Struct({\n",
        "        'source_type': pl.List(pl.Int64),\n",
        "        'action_type': pl.List(pl.Int64),\n",
        "        'product_id': pl.List(pl.Int64),\n",
        "        'lengths': pl.List(pl.Int64), # длина каждого реквеста\n",
        "        'num_requests': pl.List(pl.Int64) # общее количество реквестов у этого пользователя\n",
        "    })\n",
        "\n",
        "    def __init__(self, min_length: int, max_length: int):\n",
        "        self._min_length: int = min_length\n",
        "        self._max_length: int = max_length\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
        "        pass\n",
        "\n",
        "    def get_empty_frame(self, candidates=False):\n",
        "        return pl.DataFrame(schema=pl.Schema({\n",
        "            'history': self.HISTORY_SCHEMA,\n",
        "            **({'candidates': self.CANDIDATES_SCHEMA} if candidates else {})\n",
        "        }))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34414554",
      "metadata": {
        "id": "34414554"
      },
      "source": [
        "Структура, которая:\n",
        "- накапливает history для пользователя и оставлять последние `max_length`\n",
        "- умеет обращаться по индексу к событию истории\n",
        "- имеет метод `get(self, targets_ids)`, который превращает `self._data` в dict в соотвествии со схемой `HISTORY_SCHEMA`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c9597d",
      "metadata": {
        "id": "e1c9597d"
      },
      "outputs": [],
      "source": [
        "class HistoryDeque:\n",
        "    def __init__(self, max_length=512):\n",
        "        self._data = deque([], maxlen=max_length)\n",
        "\n",
        "    def append(self, x):\n",
        "        self._data.append(x)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self._data))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._data[idx]\n",
        "\n",
        "    def get(self, targets_inds=None):\n",
        "        \"\"\"\n",
        "        Retrieves a dictionary containing various attributes of the dataset samples.\n",
        "\n",
        "        If `targets_inds` is not provided, it automatically identifies indices of samples where the `target` is 1.\n",
        "\n",
        "        @param targets_inds: List of indices of target samples. If None, it will be determined based on samples with target value 1.\n",
        "        @return: Dictionary with keys ['source_type', 'action_type', 'product_id', 'position', 'targets_inds', 'targets_lengths', 'lengths']\n",
        "                Each key maps to a list or value representing the respective attribute of the dataset samples.\n",
        "        \"\"\"\n",
        "        if targets_inds is None:\n",
        "            targets_inds = [i for i, value in enumerate(self._data)\n",
        "                                        if value['target'] == 1]\n",
        "\n",
        "        history = {'source_type': [stori['source_type'] for stori in self._data],\n",
        "                    'action_type': [stori['action_type'] for stori in self._data],\n",
        "                    'product_id': [stori['product_id'] for stori in self._data],\n",
        "                    'position': list(range(len(self._data))),\n",
        "                    'targets_inds': targets_inds,\n",
        "                    'targets_lengths': [len(targets_inds)],\n",
        "                    'lengths': [len(self._data)]}\n",
        "\n",
        "\n",
        "        return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49cfc0dc",
      "metadata": {
        "id": "49cfc0dc"
      },
      "source": [
        "На основе функции `get_pretrain_data` реализуем `PretrainMapper`, который будет по данном пользователю выдавать обучающий пример в нужном формате."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd0a3f4",
      "metadata": {
        "id": "7dd0a3f4"
      },
      "outputs": [],
      "source": [
        "class PretrainMapper(Mapper):\n",
        "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
        "        \"\"\"\n",
        "        Processes a group of data by maintaining a history of rows up to a specified maximum length.\n",
        "        If the history meets the minimum length requirement and contains at least one target, it returns\n",
        "        a DataFrame with the history. Otherwise, it returns an empty DataFrame.\n",
        "\n",
        "        @param group: A Polars DataFrame containing the group of data to process.\n",
        "        @return: A Polars DataFrame containing the history if conditions are met; otherwise, an empty DataFrame.\n",
        "        \"\"\"\n",
        "        deque = HistoryDeque(self._max_length)\n",
        "        events_generator = ensure_sorted_by_timestamp(group.to_struct())\n",
        "\n",
        "        for event in events_generator:\n",
        "            deque.append(event)\n",
        "\n",
        "        if len(deque) > self._min_length:\n",
        "            return pl.DataFrame([{'history': deque.get()}], schema=pl.Schema({'history': Mapper.HISTORY_SCHEMA}))\n",
        "\n",
        "        else:\n",
        "            return self.get_empty_frame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d41d08d",
      "metadata": {
        "id": "5d41d08d"
      },
      "outputs": [],
      "source": [
        "def get_pretrain_data(train_history: pl.DataFrame,\n",
        "                      valid_history: pl.DataFrame,\n",
        "                      min_length: int = 5,\n",
        "                      max_length: int = 4096) -> pl.DataFrame:\n",
        "    mapper = PretrainMapper(\n",
        "        min_length=min_length,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "    train_data = (\n",
        "        train_history.with_columns(target=pl.lit(1))\n",
        "        .sort(['user_id', 'timestamp'])\n",
        "        .group_by('user_id')\n",
        "        .map_groups(mapper)\n",
        "    )\n",
        "\n",
        "    valid_data = (\n",
        "        pl.concat([\n",
        "            train_history.with_columns(target=pl.lit(0)),\n",
        "            valid_history.with_columns(target=pl.lit(1))\n",
        "        ], how='diagonal')\n",
        "        .sort(['user_id', 'timestamp'])\n",
        "        .group_by('user_id')\n",
        "        .map_groups(mapper)\n",
        "    )\n",
        "\n",
        "    return train_data, valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7d7425",
      "metadata": {
        "id": "9d7d7425"
      },
      "outputs": [],
      "source": [
        "pretrain_train_data, pretrain_valid_data = get_pretrain_data(train_history, valid_history, min_length=5, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8hWVOKSwq77J",
      "metadata": {
        "collapsed": true,
        "id": "8hWVOKSwq77J"
      },
      "outputs": [],
      "source": [
        "pretrain_valid_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d18672be",
      "metadata": {
        "id": "d18672be"
      },
      "source": [
        "## 4. Реализуем свой torch.nn.utils.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da2be818",
      "metadata": {
        "id": "da2be818"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import polars as pl\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5764444",
      "metadata": {
        "id": "d5764444"
      },
      "outputs": [],
      "source": [
        "def convert_dict_to_tensor(data_dict):\n",
        "    \"\"\"\n",
        "    Recursively converts lists within a dictionary to PyTorch tensors with dtype=torch.int64.\n",
        "\n",
        "    @param data_dict: A dictionary potentially containing nested dictionaries and lists.\n",
        "    @return: A new dictionary with the same structure as `data_dict`, but with lists converted to PyTorch tensors.\n",
        "    \"\"\"\n",
        "    if not isinstance(data_dict, dict):\n",
        "        if isinstance(data_dict, str):\n",
        "            return data_dict\n",
        "        return torch.tensor(data_dict, dtype=torch.int64)\n",
        "    else:\n",
        "        new_dict = {}\n",
        "        for key in data_dict:\n",
        "            new_dict[key] = convert_dict_to_tensor(data_dict[key])\n",
        "    return new_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc80b148",
      "metadata": {
        "id": "cc80b148"
      },
      "outputs": [],
      "source": [
        "def test_convert_dict_to_tensor_basic():\n",
        "    input_data = {\n",
        "        'a': [1, 2, 3],\n",
        "        'b': {\n",
        "            'c': [4, 5],\n",
        "            'd': 6\n",
        "        },\n",
        "        'e': 'text'\n",
        "    }\n",
        "\n",
        "    result = convert_dict_to_tensor(input_data)\n",
        "    print(result)\n",
        "\n",
        "    assert isinstance(result['a'], torch.Tensor)\n",
        "    assert result['a'].dtype == torch.int64\n",
        "    assert result['a'].tolist() == [1, 2, 3]\n",
        "\n",
        "    assert isinstance(result['b'], dict)\n",
        "    assert isinstance(result['b']['c'], torch.Tensor)\n",
        "    assert result['b']['c'].dtype == torch.int64\n",
        "    assert result['b']['c'].tolist() == [4, 5]\n",
        "\n",
        "    assert result['b']['d'] == 6\n",
        "    assert result['e'] == 'text'\n",
        "\n",
        "test_convert_dict_to_tensor_basic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f256020",
      "metadata": {
        "id": "4f256020"
      },
      "outputs": [],
      "source": [
        "class LavkaDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df: pl.DataFrame) -> 'LavkaDataset':\n",
        "        converted_data = [convert_dict_to_tensor(group) for group in df.to_struct()]\n",
        "\n",
        "        return cls(converted_data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b9e3b2",
      "metadata": {
        "id": "96b9e3b2"
      },
      "outputs": [],
      "source": [
        "print(\"Creating train dataset ...\")\n",
        "train_ds = LavkaDataset.from_dataframe(pretrain_train_data)\n",
        "print(\"Creating valid dataset ...\")\n",
        "valid_ds = LavkaDataset.from_dataframe(pretrain_valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96837a5f",
      "metadata": {
        "id": "96837a5f"
      },
      "source": [
        "## 5. Реализуем основной backbone модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11db0387",
      "metadata": {
        "id": "11db0387"
      },
      "source": [
        "Реализуем класс ResNet-блока согласно следующим формулам:\n",
        "\n",
        "Для входа $x\\in\\mathbb{R}^{\\text{batch}\\times d}$ вычислить:  \n",
        "$$\n",
        "    \\begin{aligned}\n",
        "    z &= xW + b,\\\\\n",
        "    a &= \\mathrm{ReLU}(z),\\\\\n",
        "    d'&= \\mathrm{Dropout}(a),\\\\\n",
        "    y &= \\mathrm{LayerNorm}\\bigl(x + d'\\bigr).\n",
        "    \\end{aligned}\n",
        "$$  \n",
        "В компактном виде:  \n",
        "$$\n",
        "    y = \\mathrm{LayerNorm}\\Bigl(x + \\mathrm{Dropout}\\bigl(\\mathrm{ReLU}(xW + b)\\bigr)\\Bigr)\\,.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "756010dd",
      "metadata": {
        "id": "756010dd"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, embedding_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        identity = x\n",
        "        out = self.linear(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.layer_norm(identity + out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb46dcf3",
      "metadata": {
        "id": "cb46dcf3"
      },
      "outputs": [],
      "source": [
        "def test_resnet_output_shape():\n",
        "    embedding_dim = 32\n",
        "    batch_size = 8\n",
        "    model = ResNet(embedding_dim)\n",
        "    x = torch.randn(batch_size, embedding_dim)\n",
        "    out = model(x)\n",
        "    assert out.shape == (batch_size, embedding_dim)\n",
        "\n",
        "test_resnet_output_shape()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6016c09a",
      "metadata": {
        "id": "6016c09a"
      },
      "source": [
        "Реализуем `ContextEncoder`, `ItemEncoder` и `ActionEncoder`. На вход они принимают torch.tensor с индексами размера (seq_len,), а на выходе получают torch.tensor с соотвествующими векторами размера (seq_len, embedding_dim)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MkvpCmih840Q",
      "metadata": {
        "id": "MkvpCmih840Q"
      },
      "outputs": [],
      "source": [
        "print(f'длинна action {len(preprocessor.mapping_action_types)}')\n",
        "print(f'длинна item {len(preprocessor.mapping_product_ids)}')\n",
        "print(f'длинна source {len(preprocessor.mapping_source_types)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf716125",
      "metadata": {
        "id": "cf716125"
      },
      "outputs": [],
      "source": [
        "class ContextEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(13, embedding_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.embeddings(inputs)\n",
        "\n",
        "\n",
        "class ItemEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(26522, embedding_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.embeddings(inputs)\n",
        "\n",
        "\n",
        "class ActionEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(4, embedding_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.embeddings(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_seq_len: int = 512, embedding_dim: int= 64):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_len, embedding_dim)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim)\n",
        "        )\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, pos: torch.Tensor) -> torch.Tensor:\n",
        "        return self.pe[0].index_select(0, pos.flatten())"
      ],
      "metadata": {
        "id": "-bk60mvsGe4V"
      },
      "id": "-bk60mvsGe4V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111d85db",
      "metadata": {
        "id": "111d85db"
      },
      "outputs": [],
      "source": [
        "def test_context_encoder_shape():\n",
        "    embedding_dim = 16\n",
        "    batch_size = 5\n",
        "    seq_len = 7\n",
        "    model = ContextEncoder(embedding_dim=embedding_dim)\n",
        "    x = torch.randint(0, 4, (batch_size, seq_len))\n",
        "    out = model(x)\n",
        "    assert out.shape == (batch_size, seq_len, embedding_dim)\n",
        "test_context_encoder_shape()\n",
        "\n",
        "def test_item_encoder_shape():\n",
        "    embedding_dim = 20\n",
        "    batch_size = 6\n",
        "    seq_len = 10\n",
        "    model = ItemEncoder(embedding_dim=embedding_dim)\n",
        "    x = torch.randint(0, 20000, (batch_size, seq_len))\n",
        "    out = model(x)\n",
        "    assert out.shape == (batch_size, seq_len, embedding_dim)\n",
        "test_item_encoder_shape()\n",
        "\n",
        "def test_action_encoder_shape():\n",
        "    embedding_dim = 12\n",
        "    batch_size = 4\n",
        "    seq_len = 3\n",
        "    model = ActionEncoder(embedding_dim=embedding_dim)\n",
        "    x = torch.randint(0, 4, (batch_size, seq_len))\n",
        "    out = model(x)\n",
        "    assert out.shape == (batch_size, seq_len, embedding_dim)\n",
        "test_action_encoder_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24183263",
      "metadata": {
        "id": "24183263"
      },
      "outputs": [],
      "source": [
        "def get_mask(lengths):\n",
        "    \"\"\"\n",
        "    Generates a mask tensor based on the given sequence lengths.\n",
        "\n",
        "    The mask is a boolean tensor where each row corresponds to a sequence and contains\n",
        "    True values up to the length of the sequence and False values thereafter.\n",
        "\n",
        "    @param lengths: A 1D tensor containing the lengths of sequences.\n",
        "    @return: A 2D boolean tensor where each row has True up to the corresponding sequence length.\n",
        "    \"\"\"\n",
        "    max_length = max(lengths)\n",
        "    arange_tensor = torch.arange(max_length, device=lengths.device)\n",
        "\n",
        "    return (arange_tensor < lengths.unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa156c03",
      "metadata": {
        "id": "fa156c03"
      },
      "outputs": [],
      "source": [
        "def test_get_mask():\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    expected_mask = torch.tensor([\n",
        "        [True, True, False],\n",
        "        [True, True, True],\n",
        "        [True, False, False]\n",
        "    ])\n",
        "    assert torch.equal(get_mask(lengths), expected_mask)\n",
        "\n",
        "test_get_mask()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f63da84",
      "metadata": {
        "id": "9f63da84"
      },
      "source": [
        "Реализуем `ModelBackbone`. Эта часть модели является общей для pretrain и finetune. Она кодируется входные события, преобразует их в нужный для трансформера формат `(batch_size, seq_len, embedding_dim)`, прогоняет через них трансформер и возвращает три поля: выходы трансформера, вектора товаров и вектора feedback-ов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f5edfc",
      "metadata": {
        "id": "21f5edfc"
      },
      "outputs": [],
      "source": [
        "class ModelBackbone(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_dim=64,\n",
        "                 num_heads=2,\n",
        "                 max_seq_len=512,\n",
        "                 dropout_rate=0.2,\n",
        "                 num_transformer_layers=2):\n",
        "        super().__init__()\n",
        "        self.context_encoder = ContextEncoder(embedding_dim)\n",
        "        self.item_encoder = ItemEncoder(embedding_dim)\n",
        "        self.action_encoder = ActionEncoder(embedding_dim)\n",
        "        self.position_embeddings = PositionalEncoding(max_seq_len, embedding_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=embedding_dim * 4,\n",
        "            dropout=dropout_rate,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_transformer_layers)\n",
        "        self._embedding_dim = embedding_dim\n",
        "\n",
        "    @property\n",
        "    def embedding_dim(self):\n",
        "        return self._embedding_dim\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        context_embeddings = self.context_encoder(inputs['history']['source_type'])\n",
        "        item_embeddings = self.item_encoder(inputs['history']['product_id'])\n",
        "        action_embeddings = self.action_encoder(inputs['history']['action_type'])\n",
        "        position_embedding = self.position_embeddings(inputs['history']['position'])\n",
        "\n",
        "        padding_mask = get_mask(inputs['history']['lengths'])\n",
        "        batch_size, seq_len = padding_mask.shape\n",
        "\n",
        "        token_embeddings = item_embeddings.new_zeros(\n",
        "            batch_size, seq_len, self.embedding_dim, device=context_embeddings.device)\n",
        "\n",
        "        summed_embs = (context_embeddings + item_embeddings\n",
        "                       + action_embeddings + position_embedding)\n",
        "\n",
        "        token_embeddings[padding_mask] = summed_embs\n",
        "\n",
        "        source_embeddings = self.transformer_encoder(\n",
        "            token_embeddings,\n",
        "            mask=torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device=context_embeddings.device),\n",
        "            src_key_padding_mask=~padding_mask)\n",
        "\n",
        "        return {\n",
        "            'source_embeddings': source_embeddings[padding_mask],\n",
        "            'item_embeddings': item_embeddings.squeeze(),\n",
        "            'context_embeddings': context_embeddings.squeeze()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b07d58",
      "metadata": {
        "id": "49b07d58"
      },
      "outputs": [],
      "source": [
        "def test_model_backbone():\n",
        "    sample = {\n",
        "        'history': {\n",
        "            'source_type': torch.tensor([[1, 1, 7, 1, 1,]]),\n",
        "            'action_type': torch.tensor([[2, 2, 2, 1, 2]]),\n",
        "            'product_id': torch.tensor([[19210,  8368,  5165,  5326, 12476]]),\n",
        "            'position': torch.tensor([[0, 1, 2, 3, 4]]),\n",
        "            'targets_inds': torch.tensor([[0, 1, 2]]),\n",
        "            'targets_lengths': torch.tensor([3]),\n",
        "            'lengths': torch.tensor([5])\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    backbone = ModelBackbone()\n",
        "    output = backbone(sample)\n",
        "    print(output['source_embeddings'].shape)\n",
        "    print(output['item_embeddings'].shape)\n",
        "    print(output['context_embeddings'].shape)\n",
        "    assert output['source_embeddings'].shape == (5, 64)\n",
        "    assert output['item_embeddings'].shape == (5, 64)\n",
        "    assert output['context_embeddings'].shape == (5, 64)\n",
        "\n",
        "test_model_backbone()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d87649",
      "metadata": {
        "id": "30d87649"
      },
      "source": [
        "## 6. Реализуем pretrain модель"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a95f2cf2",
      "metadata": {
        "id": "a95f2cf2"
      },
      "source": [
        "#### Головы (heads)\n",
        "\n",
        "- **User–context fusion**  \n",
        "      Последовательность ResNet-блоков, свёртка размерности `2D → D`. На входе конкатенация `source_embeddings ∥ context_embeddings`.  \n",
        "- **Candidate projector**  \n",
        "      Три ResNet-блока, преобразующие эмбеддинг товара из `D → D`.  \n",
        "- **Classifier**  \n",
        "      Три ResNet-блока, затем линейный слой `3D → 3`, для предсказания типа следующего действия из трёх возможных (cart, click, purchase).  \n",
        "- **Параметр τ**  \n",
        "      Скаляp-коэффициент `τ = clip(exp(τ_raw), τ_min, τ_max)` для масштабирования скалярных произведений – температура в contrastive-лоссе.\n",
        "\n",
        "\n",
        "#### Формулы лоссов\n",
        "\n",
        "Обозначения:  \n",
        "- $u_i \\in \\mathbb{R}^D$ – нормализованный вектор пользователя для i-го примера.  \n",
        "- $c_i \\in \\mathbb{R}^D$ – нормализованный вектор кандидата (позитивного товара) для i-го примера.  \n",
        "- $\\{n_{ij}\\}_{j=1}^M\\subset\\mathbb{R}^D$ – нормализованные векторы $M$ негативных товаров (весь каталог товаров минус один товар, позитивный).  \n",
        "- $\\text{temp}>0$ – «температура» (скаляр).  \n",
        "- $K= M+1$ – общее число кандидатов (1 позитивный + M негативных). Количество товаров во всем каталоге будет $1 + M$.\n",
        "\n",
        "1. **Retrieval loss** (контрастивный softmax-лосс)  \n",
        "   Для каждого примера $i$ вычисляем скалярные логиты:  \n",
        "   $$\n",
        "     \\ell_i = [\\,\\underbrace{u_i^\\top c_i}_{\\text{позитивный логит}} \\,\\big|\\,\n",
        "               \\underbrace{u_i^\\top n_{i1},\\,u_i^\\top n_{i2},\\,\\dots,\\,u_i^\\top n_{iM}}_{\\text{негативные логиты}}] \\;\\times\\;\\\\text{temp}\n",
        "   $$\n",
        "   Затем лосс  \n",
        "   $$\n",
        "     \\mathcal{L}_{\\mathrm{retr}}\n",
        "     = -\\frac1N \\sum_{i=1}^N \\log\\frac{\\exp\\bigl(u_i^\\top c_i \\,\\text{temp}\\bigr)}\n",
        "                                      {\\exp\\bigl(u_i^\\top c_i \\,\\text{temp}\\bigr)\n",
        "                                     + \\sum_{j=1}^M \\exp\\bigl(u_i^\\top n_{ij}\\,\\text{temp}\\bigr)}.\n",
        "   $$\n",
        "\n",
        "2. **Action loss** (кросс-энтропия)  \n",
        "   Для каждого положительного шага $i$ модель выдаёт логиты $\\mathbf{z}_i \\in \\mathbb{R}^3$ по трём классам действий, а истинная метка $y_i\\in\\{0,1,2\\}$.  \n",
        "   $$\n",
        "     \\mathcal{L}_{\\mathrm{action}}\n",
        "     = -\\frac1N \\sum_{i=1}^N \\sum_{k=0}^2 \\delta_{y_i=k}\\,\\log\\bigl(\\mathrm{softmax}(\\mathbf{z}_i)_k\\bigr),\n",
        "   $$\n",
        "   где $\\mathrm{softmax}(\\mathbf{z})_k = \\frac{e^{z_k}}{\\sum_{m=0}^2 e^{z_m}}$.\n",
        "\n",
        "3. **Итоговый лосс**  \n",
        "   $$\n",
        "     \\mathcal{L}\n",
        "     = \\mathcal{L}_{\\mathrm{retr}}\n",
        "       \\;+\\; 10 \\times \\mathcal{L}_{\\mathrm{action}}.\n",
        "   $$\n",
        "   Перевзвешиваем action часть т.к. у нее сильно меньше масштаб."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250b7f84",
      "metadata": {
        "id": "250b7f84"
      },
      "outputs": [],
      "source": [
        "class PretrainModel(nn.Module):\n",
        "    MIN_TEMPERATURE = 0.01\n",
        "    MAX_TEMPERATURE = 100\n",
        "\n",
        "    def __init__(self,\n",
        "                 backbone,\n",
        "                 embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.user_context_fusion = nn.Sequential(\n",
        "            ResNet(2 * embedding_dim),\n",
        "            ResNet(2 * embedding_dim),\n",
        "            ResNet(2 * embedding_dim),\n",
        "            nn.Linear(2 * embedding_dim, embedding_dim),\n",
        "        )\n",
        "        self.candidate_projector = nn.Sequential(\n",
        "            ResNet(embedding_dim),\n",
        "            ResNet(embedding_dim),\n",
        "            ResNet(embedding_dim),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            ResNet(3 * embedding_dim),\n",
        "            ResNet(3 * embedding_dim),\n",
        "            ResNet(3 * embedding_dim),\n",
        "            nn.Linear(3 * embedding_dim, 3),\n",
        "        )\n",
        "        self._embedding_dim = embedding_dim\n",
        "        self.tau = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
        "\n",
        "        self.cross_entr_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    @property\n",
        "    def embedding_dim(self):\n",
        "        return self._embedding_dim\n",
        "\n",
        "    @property\n",
        "    def temperature(self):\n",
        "        return torch.clip(torch.exp(self.tau), min=self.MIN_TEMPERATURE, max=self.MAX_TEMPERATURE)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        backbone_outputs = self.backbone(inputs)\n",
        "        source_embeddings = backbone_outputs['source_embeddings']\n",
        "        item_embeddings = backbone_outputs['item_embeddings']\n",
        "        context_embeddings = backbone_outputs['context_embeddings']\n",
        "\n",
        "        lengths = inputs['history']['lengths']\n",
        "        offsets = torch.cumsum(lengths, dim=0) - lengths\n",
        "        target_mask = torch.full((sum(lengths).item(),), False, dtype=torch.bool, device=lengths.device)\n",
        "        target_inds = torch.repeat_interleave(offsets, inputs['history']['targets_lengths']) + inputs['history']['targets_inds']\n",
        "        target_mask[target_inds] = True\n",
        "        non_first_element = torch.full((sum(lengths).item(),), True, dtype=torch.bool, device=lengths.device)\n",
        "        non_first_element[offsets] = False\n",
        "        source_mask = torch.roll(non_first_element & target_mask, -1)\n",
        "\n",
        "        source_embeddings = source_embeddings[source_mask]\n",
        "        context_embeddings = context_embeddings[non_first_element & target_mask]\n",
        "        item_embeddings = item_embeddings[non_first_element & target_mask]\n",
        "\n",
        "\n",
        "        # calc retrieval loss\n",
        "        user_embeddings = torch.nn.functional.normalize(self.user_context_fusion(torch.cat([source_embeddings, context_embeddings], dim=-1)))\n",
        "        candidate_embeddings = torch.nn.functional.normalize(\n",
        "                                self.candidate_projector(\n",
        "                                self.backbone.item_encoder.embeddings(inputs['history']['product_id'][target_mask & non_first_element])))\n",
        "        negative_embeddings = torch.nn.functional.normalize(self.candidate_projector(self.backbone.item_encoder.embeddings.weight))\n",
        "        pos_logits = torch.sum(user_embeddings * candidate_embeddings, dim=-1) * self.temperature\n",
        "        neg_logits = user_embeddings @ negative_embeddings.T * self.temperature\n",
        "        next_positive_prediction_loss = - torch.mean(\n",
        "                                          (pos_logits) - (torch.logsumexp(neg_logits, dim=-1))\n",
        "                                                  )\n",
        "\n",
        "        # calc action loss\n",
        "        logits = self.classifier(torch.cat([source_embeddings, context_embeddings, item_embeddings], dim=-1))\n",
        "        targets = inputs['history']['action_type'][non_first_element & target_mask] - 1\n",
        "        feedback_prediction_loss = self.cross_entr_loss(logits, targets)\n",
        "\n",
        "        return {\n",
        "            'next_positive_prediction_loss': next_positive_prediction_loss,\n",
        "            'feedback_prediction_loss': feedback_prediction_loss,\n",
        "            'loss': next_positive_prediction_loss + feedback_prediction_loss * 10\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ff38e6",
      "metadata": {
        "id": "c3ff38e6"
      },
      "source": [
        "## 7. (0.5 балл) Обучим pretrain модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98d2b65",
      "metadata": {
        "id": "a98d2b65"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Collates a batch of samples from a dataset.\n",
        "\n",
        "    This function is designed to handle batches where each sample is a dictionary.\n",
        "    It recursively collates values associated with the same keys across all samples in the batch.\n",
        "    For tensor values, it concatenates them along the first dimension.\n",
        "    For dictionary values, it applies the same collation logic recursively.\n",
        "    For other types of values, it simply aggregates them into a list.\n",
        "\n",
        "    @param batch: A list of samples, where each sample is a dictionary.\n",
        "    @return: A dictionary with the same keys as the samples, where each value is either\n",
        "             a concatenated tensor, a recursively collated dictionary, or a list of values.\n",
        "    \"\"\"\n",
        "    if isinstance(batch, list) and isinstance(batch[0], dict):\n",
        "        batched_dict = {}\n",
        "        for key in batch[0].keys():\n",
        "            list_of_values = [item[key] for item in batch]\n",
        "            batched_dict[key] = collate_fn(list_of_values)\n",
        "        return batched_dict\n",
        "    elif isinstance(batch, list) and isinstance(batch[0], torch.Tensor):\n",
        "        return torch.cat(batch, dim=0)\n",
        "    elif isinstance(batch, list):\n",
        "        return batch\n",
        "    else:\n",
        "        return batch\n",
        "\n",
        "def move_to_device(batch, device):\n",
        "    \"\"\"\n",
        "    Moves a batch of data to a specified device (e.g., CPU or GPU).\n",
        "\n",
        "    Args:\n",
        "        batch (torch.Tensor or dict): The batch of data to move. Can be a single tensor or a dictionary of tensors.\n",
        "        device (torch.device): The target device to which the batch should be moved.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor or dict: The batch of data moved to the specified device.\n",
        "                             If the input is a dictionary, the returned value will be a dictionary with the same keys\n",
        "                             and values moved to the specified device.\n",
        "    \"\"\"\n",
        "    if isinstance(batch, torch.Tensor):\n",
        "        return batch.to(device)\n",
        "    elif isinstance(batch, dict):\n",
        "        return {key: move_to_device(value, device) for key, value in batch.items()}\n",
        "    elif isinstance(batch, list):\n",
        "        return [move_to_device(item, device) for item in batch]\n",
        "    elif isinstance(batch, tuple):\n",
        "        return tuple(move_to_device(item, device) for item in batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5077c9b9",
      "metadata": {
        "id": "5077c9b9"
      },
      "outputs": [],
      "source": [
        "def test_collate_fn_basic():\n",
        "    batch = [\n",
        "        {\n",
        "            'x': torch.tensor([1, 2]),\n",
        "            'y': {\n",
        "                'z': torch.tensor([[10], [20]]),\n",
        "                'w': 5\n",
        "            },\n",
        "            's': 'foo'\n",
        "        },\n",
        "        {\n",
        "            'x': torch.tensor([3, 4]),\n",
        "            'y': {\n",
        "                'z': torch.tensor([[30], [40]]),\n",
        "                'w': 6\n",
        "            },\n",
        "            's': 'bar'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    result = collate_fn(batch)\n",
        "\n",
        "    assert isinstance(result['x'], torch.Tensor)\n",
        "    assert result['x'].tolist() == [1, 2, 3, 4]\n",
        "\n",
        "    assert isinstance(result['y'], dict)\n",
        "    assert isinstance(result['y']['z'], torch.Tensor)\n",
        "    assert result['y']['z'].tolist() == [[10], [20], [30], [40]]\n",
        "    assert result['y']['w'] == [5, 6]\n",
        "\n",
        "    assert result['s'] == ['foo', 'bar']\n",
        "test_collate_fn_basic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef41d30",
      "metadata": {
        "id": "1ef41d30"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "\n",
        "def train_pretrain_model(model, train_loader, valid_loader, optimizer, scheduler, num_epochs, device):\n",
        "    global_cnt = 0\n",
        "    prev_valid_loss = None\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        action_losses = []\n",
        "        retrieval_losses = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            batch = move_to_device(batch, device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch)\n",
        "            loss = output['loss']\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "            action_losses.append(output['feedback_prediction_loss'].item())\n",
        "            retrieval_losses.append(output['next_positive_prediction_loss'].item())\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {mean(train_losses):.6f}, Train Feedback Loss: {mean(action_losses):.6f}, Train NPP Loss: {mean(retrieval_losses):.6f}\")\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        valid_losses = []\n",
        "        action_losses = []\n",
        "        retrieval_losses = []\n",
        "        with torch.inference_mode():\n",
        "            for batch in tqdm(valid_loader):\n",
        "                if len(batch['history']['targets_inds']) == 0:\n",
        "                    continue\n",
        "                batch = move_to_device(batch, device)\n",
        "                output = model(batch)\n",
        "                loss = output['loss']\n",
        "                valid_losses.append(loss.item())\n",
        "                action_losses.append(output['feedback_prediction_loss'].item())\n",
        "                retrieval_losses.append(output['next_positive_prediction_loss'].item())\n",
        "\n",
        "        avg_valid_loss = mean(valid_losses)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Valid Loss: {avg_valid_loss:.6f}, Valid Feedback Loss: {mean(action_losses):.6f}, Valid NPP Loss: {mean(retrieval_losses):.6f}\")\n",
        "\n",
        "        if prev_valid_loss is None or prev_valid_loss > avg_valid_loss:\n",
        "            global_cnt = 0\n",
        "            prev_valid_loss = avg_valid_loss\n",
        "            with torch.no_grad():\n",
        "                torch.save(model, './pretrain.pt')\n",
        "        else:\n",
        "            global_cnt += 1\n",
        "            if global_cnt == 10:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0afde462",
      "metadata": {
        "id": "0afde462"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "batch_size = 8\n",
        "warmup_epochs = 4\n",
        "start_factor = 0.1\n",
        "num_epochs = 100\n",
        "\n",
        "embedding_dim = 64\n",
        "num_heads = 2\n",
        "max_seq_len = 512\n",
        "dropout_rate = 0.2\n",
        "num_transformer_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb8af26",
      "metadata": {
        "id": "abb8af26"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c8d4a9",
      "metadata": {
        "id": "05c8d4a9"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "backbone = ModelBackbone(embedding_dim=embedding_dim,\n",
        "                        num_heads=num_heads,\n",
        "                        max_seq_len=max_seq_len,\n",
        "                        dropout_rate=dropout_rate,\n",
        "                        num_transformer_layers=num_transformer_layers).to(device)\n",
        "model_pretrain = PretrainModel(backbone=backbone,\n",
        "                             embedding_dim=embedding_dim).to(device)\n",
        "optimizer = optim.AdamW(model_pretrain.parameters(), lr=lr, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=start_factor,\n",
        "    total_iters=warmup_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8506243",
      "metadata": {
        "collapsed": true,
        "id": "e8506243"
      },
      "outputs": [],
      "source": [
        "train_pretrain_model(model_pretrain, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e66695",
      "metadata": {
        "id": "c2e66695"
      },
      "outputs": [],
      "source": [
        "def best_metric_model(valid_loader):\n",
        "    test_model = torch.load('./pretrain.pt', weights_only=False)\n",
        "    valid_losses = []\n",
        "    with torch.inference_mode():\n",
        "        for batch in tqdm(valid_loader):\n",
        "            if len(batch['history']['targets_inds']) == 0:\n",
        "                    continue\n",
        "            batch = move_to_device(batch, device)\n",
        "            output = test_model(batch)\n",
        "            loss = output['loss']\n",
        "            valid_losses.append(loss.item())\n",
        "    print(mean(valid_losses))\n",
        "\n",
        "best_metric_model(valid_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b660b6c",
      "metadata": {
        "id": "7b660b6c"
      },
      "source": [
        "## 8. Подготовка данных для finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2366cc6",
      "metadata": {
        "id": "d2366cc6"
      },
      "source": [
        "Схемы для candidates:\n",
        "```python\n",
        "CANDIDATES_SCHEMA = pl.Struct({\n",
        "    'source_type': pl.List(pl.Int64),\n",
        "    'action_type': pl.List(pl.Int64),\n",
        "    'product_id': pl.List(pl.Int64),\n",
        "    'lengths': pl.List(pl.Int64), # длина каждого реквеста\n",
        "    'num_requests': pl.List(pl.Int64) # общее количество реквестов у этого пользователя\n",
        "})\n",
        "```\n",
        "\n",
        "Пример семпла:\n",
        "\n",
        "```python\n",
        "finetune_train_sample = {\n",
        "    'history': {...},\n",
        "    'candidates': {\n",
        "        'source_type': [1, 2, 3],\n",
        "        'action_type': [1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "        'product_id': [10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
        "        'lengths': [3, 3, 3],\n",
        "        'num_requests': 3\n",
        "    }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b77da9",
      "metadata": {
        "id": "10b77da9"
      },
      "outputs": [],
      "source": [
        "class Candidates:\n",
        "    def __init__(self, max_requests_size):\n",
        "        self._data = deque([], maxlen=max_requests_size)\n",
        "\n",
        "    def append(self, x):\n",
        "        if x['request_id']:\n",
        "            self._data.append(x)\n",
        "\n",
        "    def popleft(self):\n",
        "        return self._data.popleft()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "\n",
        "    def get(self):\n",
        "        \"\"\"\n",
        "        Aggregates data from the internal _data attribute into a structured dictionary format.\n",
        "\n",
        "        This method constructs a dictionary with keys 'source_type', 'action_type', 'product_id', 'lengths', and 'num_requests'.\n",
        "        - 'source_type' contains the source types from each sample.\n",
        "        - 'action_type' contains all action types from each sample's action_type_list flattened into a single list.\n",
        "        - 'product_id' contains all product IDs from each sample's product_id_list flattened into a single list.\n",
        "        - 'lengths' contains the length of the product_id_list for each sample.\n",
        "        - 'num_requests' contains the total number of samples.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: A dictionary with aggregated data.\n",
        "        \"\"\"\n",
        "\n",
        "        candidate_deque = {'source_type':[],\n",
        "                           'action_type':[],\n",
        "                           'product_id':[],\n",
        "                           'lengths':[],\n",
        "                           'num_requests':[len(self)]}\n",
        "\n",
        "        for x in self:\n",
        "            candidate_deque['source_type'].append(x['source_type'])\n",
        "            candidate_deque['action_type'].extend(x['action_type_list'])\n",
        "            candidate_deque['product_id'].extend(x['product_id_list'])\n",
        "            candidate_deque['lengths'].append(len(x['action_type_list']))\n",
        "\n",
        "        return candidate_deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d13bb58d",
      "metadata": {
        "id": "d13bb58d"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import bisect\n",
        "\n",
        "\n",
        "class FinetuneTrainMapper(Mapper):\n",
        "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
        "        \"\"\"\n",
        "        Processes a group of interactions to generate history and candidate sets for recommendation.\n",
        "\n",
        "        This method processes a DataFrame containing interaction data, separating actions into history and candidates based on the presence of 'action_type_list'.\n",
        "        It ensures the data is sorted by timestamp, filters candidates based on time constraints, and selects historical interactions within a specified lag range for each candidate.\n",
        "        If there are no valid candidates or insufficient history, it returns an empty DataFrame.\n",
        "\n",
        "        @param group: A Polars DataFrame containing interaction data with at least 'timestamp' and 'action_type_list' columns.\n",
        "        @return: A Polars DataFrame with 'history' and 'candidates' columns, or an empty DataFrame if no valid candidates are found.\n",
        "        \"\"\"\n",
        "        history_deque = HistoryDeque()\n",
        "        candidate_deque = Candidates(self._max_length)\n",
        "\n",
        "        history_generator = ensure_sorted_by_timestamp(group.to_struct())\n",
        "        for event in history_generator:\n",
        "            if event['action_type_list'] is None:\n",
        "                history_deque.append(event)\n",
        "\n",
        "        candidate_generator = ensure_sorted_by_timestamp(group.to_struct())\n",
        "        for event in candidate_generator:\n",
        "            if event['action_type_list']:\n",
        "                max_time = event['timestamp'] - random.randrange(2, 32) * 86400\n",
        "                target_ind = bisect.bisect_right(history_deque, max_time, key=lambda x: x['timestamp'])\n",
        "                if target_ind == 0:\n",
        "                    continue\n",
        "                event['targets_inds'] = target_ind - 1\n",
        "                candidate_deque.append(event)\n",
        "\n",
        "        targets_inds = [candidate['targets_inds'] for candidate in candidate_deque]\n",
        "\n",
        "\n",
        "        if len(candidate_deque) > self._min_length and len(history_deque) > self._min_length:\n",
        "            return pl.DataFrame([{'history': history_deque.get(targets_inds),\n",
        "                                  'candidates': candidate_deque.get()}],\n",
        "                                 schema=pl.Schema({'history': Mapper.HISTORY_SCHEMA,\n",
        "                                                  'candidates': Mapper.CANDIDATES_SCHEMA}))\n",
        "        else:\n",
        "            return self.get_empty_frame(candidates=True)\n",
        "\n",
        "class FinetuneValidMapper(Mapper):\n",
        "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
        "        \"\"\"\n",
        "        Differs only in the formation of target_inds\n",
        "        \"\"\"\n",
        "        history_deque = HistoryDeque()\n",
        "        candidate_deque = Candidates(self._max_length)\n",
        "\n",
        "        history_generator = ensure_sorted_by_timestamp(group.to_struct())\n",
        "        for event in history_generator:\n",
        "            if event['action_type_list'] is None:\n",
        "                history_deque.append(event)\n",
        "\n",
        "        candidate_generator = ensure_sorted_by_timestamp(group.to_struct())\n",
        "        for event in candidate_generator:\n",
        "            if event['action_type_list']:\n",
        "                max_time = event['timestamp']\n",
        "                target_ind = bisect.bisect_right(history_deque, max_time, key=lambda x: x['timestamp'])\n",
        "                if target_ind == 0:\n",
        "                    continue\n",
        "                event['targets_inds'] = target_ind - 1\n",
        "                candidate_deque.append(event)\n",
        "\n",
        "        targets_inds = [candidate['targets_inds'] for candidate in candidate_deque]\n",
        "\n",
        "\n",
        "        if len(candidate_deque) > self._min_length and len(history_deque) > self._min_length:\n",
        "            return pl.DataFrame([{'history': history_deque.get(targets_inds),\n",
        "                                  'candidates': candidate_deque.get()}],\n",
        "                                 schema=pl.Schema({'history': Mapper.HISTORY_SCHEMA,\n",
        "                                                  'candidates': Mapper.CANDIDATES_SCHEMA}))\n",
        "        else:\n",
        "            return self.get_empty_frame(candidates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707cfdd7",
      "metadata": {
        "id": "707cfdd7"
      },
      "outputs": [],
      "source": [
        "def get_finetune_data(train_history: pl.DataFrame,\n",
        "                      train_targets: pl.DataFrame,\n",
        "                      valid_targets: pl.DataFrame,\n",
        "                      min_length: int = 5,\n",
        "                      max_length: int = 4096) -> pl.DataFrame:\n",
        "    mapper = FinetuneTrainMapper(\n",
        "        min_length=min_length,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "    train_data = (\n",
        "        pl.concat([\n",
        "            train_history,\n",
        "            train_targets.with_columns([\n",
        "                pl.col('product_id').alias('product_id_list'),\n",
        "                pl.col('action_type').alias('action_type_list')\n",
        "            ]).drop(['product_id', 'action_type'])\n",
        "        ], how='diagonal')\n",
        "        .sort(['user_id', 'timestamp'])\n",
        "        .group_by('user_id')\n",
        "        .map_groups(mapper)\n",
        "    )\n",
        "\n",
        "    mapper = FinetuneValidMapper(\n",
        "        min_length=min_length,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "    valid_data = (\n",
        "        pl.concat([\n",
        "            train_history,\n",
        "            valid_targets.with_columns([\n",
        "                pl.col('product_id').alias('product_id_list'),\n",
        "                pl.col('action_type').alias('action_type_list')\n",
        "            ]).drop(['product_id', 'action_type'])\n",
        "        ], how='diagonal')\n",
        "        .sort(['user_id', 'timestamp'])\n",
        "        .group_by('user_id')\n",
        "        .map_groups(mapper)\n",
        "    )\n",
        "\n",
        "    return train_data, valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f663b7c",
      "metadata": {
        "id": "8f663b7c"
      },
      "outputs": [],
      "source": [
        "finetune_train_data, finetune_valid_data = get_finetune_data(train_history, train_targets, valid_targets, min_length=5, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75788228",
      "metadata": {
        "id": "75788228"
      },
      "outputs": [],
      "source": [
        "print(\"Creating train dataset ...\")\n",
        "train_ds = LavkaDataset.from_dataframe(finetune_train_data)\n",
        "print(\"Creating valid dataset ...\")\n",
        "valid_ds = LavkaDataset.from_dataframe(finetune_valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "344bdfff",
      "metadata": {
        "id": "344bdfff"
      },
      "source": [
        "## 9. Реализуем finetune модель"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecbd0611",
      "metadata": {
        "id": "ecbd0611"
      },
      "source": [
        "#### Функция make_groups: разметка элементов по «группам»\n",
        "\n",
        "Дано: вектор длин последовательностей  \n",
        "$$\n",
        "\\mathbf{l} = [\\,l_1, l_2, \\dots, l_B\\,],\\quad l_i\\in\\mathbb{N},\\;\n",
        "B=\\text{batch size}.\n",
        "$$  \n",
        "Нужно получить вектор «номеров групп» длиной  \n",
        "$$\n",
        "N = \\sum_{i=1}^B l_i\n",
        "$$\n",
        "так, чтобы первые $l_1$ элементов имели номер группы 0, следующие $l_2$ - номер 1 и т.д.  \n",
        "Результат:  \n",
        "$$\n",
        "\\mathrm{groups} = [\\,\\underbrace{0,\\dots,0}_{l_1},\\;\n",
        "\\underbrace{1,\\dots,1}_{l_2},\\;\\dots\\;,\\underbrace{B-1,\\dots,B-1}_{l_B}\\,]\\,.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cdaabe5",
      "metadata": {
        "id": "3cdaabe5"
      },
      "outputs": [],
      "source": [
        "def make_groups(lengths: torch.Tensor) -> torch.Tensor:\n",
        "    range_tensor = torch.arange(0, len(lengths), device=lengths.device)\n",
        "    return torch.repeat_interleave(range_tensor, lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee5be06",
      "metadata": {
        "id": "5ee5be06"
      },
      "outputs": [],
      "source": [
        "def test_make_groups_basic():\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    expected = torch.tensor([0, 0, 1, 1, 1, 2])\n",
        "    result = make_groups(lengths)\n",
        "    assert torch.equal(result, expected)\n",
        "\n",
        "test_make_groups_basic()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "925b500d",
      "metadata": {
        "id": "925b500d"
      },
      "source": [
        "#### Функция make_pairs: построение всех упорядоченных пар внутри групп\n",
        "\n",
        "Цель: для каждого «блока» длины $l_i$ сгенерировать всех $l_i\\times l_i$ упорядоченных пар индексов  \n",
        "$$\n",
        "( p, q ),\\quad p,q\\in\\{0,\\dots,l_i-1\\},\n",
        "$$\n",
        "а затем «развернуть» их по всему батчу. Результат - двумерный тензор shape $(2,\\,\\sum_i l_i^2)$, где\n",
        "\n",
        "- первая строка `pairs` - индексы «первого» элемента пары в пределах своего блока,  \n",
        "- вторая строка `pairs` - индексы «второго».\n",
        "\n",
        "Математически пары нумеруются так:\n",
        "$$\n",
        "\\{\\, (p,q)\\;\\big|\\;p=0..l_i-1,\\;q=0..l_i-1\\;\\}\\quad\\forall i=1..B.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92121880",
      "metadata": {
        "id": "92121880"
      },
      "outputs": [],
      "source": [
        "def make_pairs(lengths: torch.Tensor) -> torch.Tensor:\n",
        "    num_pairs_per_group = lengths**2\n",
        "    total_pairs = torch.sum(num_pairs_per_group)\n",
        "\n",
        "    group_idx = make_groups(num_pairs_per_group)\n",
        "\n",
        "    pair_offsets = torch.cumsum(num_pairs_per_group, dim=0) - num_pairs_per_group\n",
        "    local_pair_idx = torch.arange(total_pairs, device=lengths.device) - pair_offsets.repeat_interleave(num_pairs_per_group)\n",
        "\n",
        "    local_p = local_pair_idx // lengths[group_idx]\n",
        "    local_q = local_pair_idx % lengths[group_idx]\n",
        "\n",
        "    offsets = torch.cumsum(lengths, dim=0) - lengths\n",
        "    global_offsets = offsets[group_idx]\n",
        "\n",
        "    pairs_first = local_p + global_offsets\n",
        "    pairs_second = local_q + global_offsets\n",
        "\n",
        "    return torch.stack([pairs_first, pairs_second], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cebd057",
      "metadata": {
        "id": "0cebd057"
      },
      "outputs": [],
      "source": [
        "def test_make_pairs_simple():\n",
        "    lengths = torch.tensor([1, 2], dtype=torch.long)\n",
        "    expected = torch.tensor([\n",
        "        [0, 1, 1, 2, 2],\n",
        "        [0, 1, 2, 1, 2]\n",
        "    ], dtype=torch.long)\n",
        "\n",
        "    pairs = make_pairs(lengths)\n",
        "    assert pairs.shape == (2, 5)\n",
        "    assert torch.equal(pairs, expected)\n",
        "\n",
        "test_make_pairs_simple()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d085421",
      "metadata": {
        "id": "3d085421"
      },
      "source": [
        "#### Класс CalibratedPairwiseLogistic: попарная калиброванная логистическая функция потерь\n",
        "\n",
        "Идея была предложена здесь: [Calibrated Pairwise Logistic](https://arxiv.org/pdf/2211.01494). Пусть у нас есть:\n",
        "\n",
        "- логиты всех элементов: $\\mathbf{c} \\in \\mathbb{R}^N$,\n",
        "- таргеты $\\mathbf{t}\\in\\mathbb{R}^N$,\n",
        "\n",
        "Шаги:\n",
        "\n",
        "1. Генерируем все упорядоченные пары индексов внутри групп:  \n",
        "   $$\n",
        "   \\mathrm{pairs} = \\bigl[\\;I_0,\\;I_1\\bigr],\\quad\n",
        "   I_0,I_1\\in\\{0,\\dots,N-1\\}\n",
        "   $$\n",
        "2. Для каждой пары извлекаем  \n",
        "   $$\n",
        "   c_i = c_{I_0},\\quad c_j = c_{I_1},\\quad\n",
        "   t_i = t_{I_0},\\quad t_j = t_{I_1}.\n",
        "   $$\n",
        "3. Отбираем только «положительные» пары, где $t_i > t_j$. Вводим индикатор  \n",
        "   $$\n",
        "   w_{ij} =\n",
        "     \\begin{cases}\n",
        "       1,&t_i > t_j,\\\\\n",
        "       0,&\\text{иначе}.\n",
        "     \\end{cases}\n",
        "   $$\n",
        "   И считаем $W=\\sum w_{ij}$.\n",
        "4. Если $W>0$, вычисляем попарный loss для каждой положительной пары:\n",
        "   \n",
        "   а) сначала вычисляем «калиброванную вероятность» того, что $i$ лучше $j$:\n",
        "   $$\n",
        "     p_{ij}\n",
        "     = \\frac{\\sigma(c_i)}{\\sigma(c_i)+\\sigma(c_j)},\n",
        "     \\quad\n",
        "     \\sigma(x)=\\frac1{1+e^{-x}}.\n",
        "   $$\n",
        "   б) берём отрицательный логарифм правдоподобия:\n",
        "   $$\n",
        "     \\ell_{ij}\n",
        "     = -\\log p_{ij}\n",
        "     = -\\log\\frac{\\sigma(c_i)}{\\sigma(c_i)+\\sigma(c_j)}.\n",
        "   $$\n",
        "   \n",
        "5. Итоговая loss - усреднённая:\n",
        "   $$\n",
        "     \\mathcal{L}\n",
        "     = \\frac{1}{W}\\sum_{i,j} w_{ij}\\;\\ell_{ij}.\n",
        "   $$\n",
        "6. Если $W=0$ (нет ни одной пары с $t_i>t_j$), возвращаем нуль.\n",
        "\n",
        "Таким образом, CalibratedPairwiseLogistic минимизирует  \n",
        "$$\n",
        "-\\frac{1}{W}\\sum_{t_i>t_j}\\log\\frac{\\sigma(c_i)}{\\sigma(c_i)+\\sigma(c_j)},\n",
        "$$\n",
        "то есть учит давать более высокие оценки $c_i$ элементам с большим таргетом $t_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4dc5b9",
      "metadata": {
        "id": "4d4dc5b9"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CalibratedPairwiseLogistic(nn.Module):\n",
        "    def forward(self, logits, targets, lengths):\n",
        "        pairs = make_pairs(lengths)\n",
        "        targets_pairs = targets[pairs]\n",
        "        logits_pairs = logits[pairs]\n",
        "\n",
        "        w = targets_pairs[0] > targets_pairs[1]\n",
        "        ci = logits_pairs[0][w]\n",
        "        cj = logits_pairs[1][w]\n",
        "\n",
        "        if ci.numel() == 0:\n",
        "            return logits.new_tensor(0.0)\n",
        "\n",
        "        term1 = F.softplus(-ci)\n",
        "\n",
        "        log_sig_ci = -F.softplus(-ci)\n",
        "        log_sig_cj = -F.softplus(-cj)\n",
        "        term2 = torch.logaddexp(log_sig_ci, log_sig_cj)\n",
        "\n",
        "        loss = term1 + term2\n",
        "\n",
        "        #loss = F.softplus(-(ci - cj))\n",
        "\n",
        "        return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc63f57",
      "metadata": {
        "id": "ffc63f57"
      },
      "source": [
        "В FinetuneModel к сырым логитам  \n",
        "$$\\ell_i = \\langle u_i, v_i\\rangle$$  \n",
        "применяется калибровка:\n",
        "\n",
        "1. Параметр «scale» (обозначим $s$) хранится в виде логарифма, то есть в модели он задан как $\\text{scale}$, а реальный множитель берётся как  \n",
        "   $$\n",
        "     \\alpha = \\exp(\\text{scale}).\n",
        "   $$\n",
        "\n",
        "2. Параметр «bias» (обозначим $b$) - это свободный смещающий коэффициент.\n",
        "\n",
        "Калиброванный логит получается по формуле  \n",
        "$$\n",
        "  \\hat\\ell_i \\;=\\; \\frac{\\ell_i}{\\alpha} \\;+\\; b\n",
        "  \\;=\\;\n",
        "  \\frac{\\langle u_i, v_i\\rangle}{\\exp(\\text{s})} \\;+\\; b.\n",
        "$$\n",
        "\n",
        "Благодаря этому механизмy модель может автоматически подстраивать и жёсткость (разброс) логитов (через $\\alpha$), и их среднее значение (через $b$), что важно для оптимальной работы попарной логистической функции потерь."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b8ee30",
      "metadata": {
        "id": "34b8ee30"
      },
      "outputs": [],
      "source": [
        "class FinetuneModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 backbone,\n",
        "                 embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.user_context_fusion = nn.Sequential(\n",
        "            ResNet(2 * embedding_dim),\n",
        "            ResNet(2 * embedding_dim),\n",
        "            ResNet(2 * embedding_dim),\n",
        "            nn.Linear(2 * embedding_dim, embedding_dim),\n",
        "        )\n",
        "        self.candidate_projector = nn.Sequential(\n",
        "            ResNet(embedding_dim),\n",
        "            ResNet(embedding_dim),\n",
        "            ResNet(embedding_dim),\n",
        "        )\n",
        "        self._embedding_dim = embedding_dim\n",
        "        self.scale = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
        "        self.pairwise_loss = CalibratedPairwiseLogistic()\n",
        "\n",
        "    @property\n",
        "    def embedding_dim(self):\n",
        "        return self._embedding_dim\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        backbone_outputs = self.backbone(inputs)\n",
        "        source_embeddings = backbone_outputs['source_embeddings']\n",
        "\n",
        "        lengths = inputs['history']['lengths']\n",
        "        offsets = torch.cumsum(lengths, dim=0) - lengths\n",
        "\n",
        "        target_inds = torch.repeat_interleave(offsets, inputs['history']['targets_lengths']) + inputs['history']['targets_inds']\n",
        "        source_embeddings = source_embeddings[target_inds]\n",
        "        context_embeddings = self.backbone.context_encoder(inputs['candidates']['source_type'])\n",
        "        candidate_embeddings = self.backbone.item_encoder(inputs['candidates']['product_id'])\n",
        "\n",
        "        source_embeddings = torch.nn.functional.normalize(\n",
        "                                self.user_context_fusion(\n",
        "                                torch.cat([source_embeddings, context_embeddings], dim=-1)))\n",
        "\n",
        "        candidate_embeddings = torch.nn.functional.normalize(self.candidate_projector(candidate_embeddings))\n",
        "        source_embeddings = torch.repeat_interleave(source_embeddings, inputs['candidates']['lengths'], dim=0)\n",
        "        output_logits = torch.sum((candidate_embeddings * source_embeddings), dim=-1) / torch.exp(self.scale) + self.bias\n",
        "\n",
        "        return {\n",
        "            'logits': output_logits,\n",
        "            'loss': self.pairwise_loss(output_logits,\n",
        "                                       inputs['candidates']['action_type'],\n",
        "                                       inputs['candidates']['lengths'])\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d6b63f",
      "metadata": {
        "id": "65d6b63f"
      },
      "outputs": [],
      "source": [
        "def test_finetune_model():\n",
        "    sample = {\n",
        "        'history': {\n",
        "            'source_type': torch.tensor([8, 8, 8, 8, 8]),\n",
        "            'action_type': torch.tensor([1, 1, 2, 2, 1]),\n",
        "            'product_id': torch.tensor([ 3551, 17044, 10396, 10396, 10396]),\n",
        "            'position': torch.tensor([0, 1, 2, 3, 4]),\n",
        "            'targets_inds': torch.tensor([1]),\n",
        "            'targets_lengths': torch.tensor([1]),\n",
        "            'lengths': torch.tensor([5])\n",
        "        },\n",
        "        'candidates': {\n",
        "            'source_type': torch.tensor([8]),\n",
        "            'action_type': torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
        "            'product_id': torch.tensor([18391,  6750, 21647,  5339,  3171,  6150,  3454, 20012, 19954, 10690, 24020,  5551,  5699, 17388, 10396]),\n",
        "        'lengths': torch.tensor([15]),\n",
        "        'num_requests': torch.tensor([1])\n",
        "        }\n",
        "    }\n",
        "    backbone = ModelBackbone()\n",
        "    model_finetune = FinetuneModel(backbone)\n",
        "    output = model_finetune(sample)\n",
        "\n",
        "    assert output['logits'].shape == (15,)\n",
        "    assert output['loss'].shape == ()\n",
        "\n",
        "test_finetune_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e01cb1",
      "metadata": {
        "id": "f2e01cb1"
      },
      "source": [
        "## 10. Обучаем finetune модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "615e6b46",
      "metadata": {
        "id": "615e6b46"
      },
      "outputs": [],
      "source": [
        "def train_finetune_model(model, train_loader, valid_loader, optimizer, scheduler, num_epochs, device):\n",
        "    prev_valid_ndcg = None\n",
        "    global_cnt = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            batch = move_to_device(batch, device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(batch)['loss']\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {mean(train_losses):.6f}\")\n",
        "\n",
        "        model.eval()\n",
        "        valid_losses = []\n",
        "        valid_logits = []\n",
        "        valid_targets = []\n",
        "        with torch.inference_mode():\n",
        "            for batch in tqdm(valid_loader):\n",
        "                batch = move_to_device(batch, device)\n",
        "                output = model(batch)\n",
        "                loss = output['loss']\n",
        "                valid_losses.append(loss.item())\n",
        "                logits = output['logits']\n",
        "                targets = batch['candidates']['action_type']\n",
        "                lengths = batch['candidates']['lengths']\n",
        "                i = 0\n",
        "                for length in lengths:\n",
        "                    if length > 1:\n",
        "                        valid_logits.append(logits[i:i + length].cpu().numpy())\n",
        "                        valid_targets.append(targets[i:i + length].cpu().numpy())\n",
        "                    i += length\n",
        "\n",
        "        avg_valid_ndcg = 0\n",
        "        for logits, targets in zip(valid_logits, valid_targets):\n",
        "            avg_valid_ndcg += ndcg_score(targets[None,], logits[None,], k=10, ignore_ties=True)\n",
        "        avg_valid_ndcg /= len(valid_logits)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Valid Loss: {mean(valid_losses):.6f}\")\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Valid NDCG@10: {avg_valid_ndcg}\")\n",
        "\n",
        "        if prev_valid_ndcg is None or prev_valid_ndcg < avg_valid_ndcg:\n",
        "            global_cnt = 0\n",
        "            prev_valid_ndcg = avg_valid_ndcg\n",
        "            with torch.no_grad():\n",
        "                torch.save(model, './finetune.pt')\n",
        "        else:\n",
        "            global_cnt += 1\n",
        "            if global_cnt == 10:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e451a2",
      "metadata": {
        "id": "38e451a2"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "batch_size = 4\n",
        "warmup_epochs = 6\n",
        "start_factor = 0.1\n",
        "num_epochs = 100\n",
        "\n",
        "embedding_dim = 64\n",
        "num_heads = 2\n",
        "max_seq_len = 512\n",
        "dropout_rate = 0.1\n",
        "num_transformer_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48982863",
      "metadata": {
        "id": "48982863"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ca8060",
      "metadata": {
        "id": "e0ca8060"
      },
      "outputs": [],
      "source": [
        "backbone = ModelBackbone(embedding_dim=embedding_dim,\n",
        "                        num_heads=num_heads,\n",
        "                        max_seq_len=max_seq_len,\n",
        "                        dropout_rate=dropout_rate,\n",
        "                        num_transformer_layers=num_transformer_layers).to(device)\n",
        "\n",
        "model_finetune = FinetuneModel(backbone=backbone,\n",
        "                             embedding_dim=embedding_dim).to(device).to(device)\n",
        "optimizer = optim.AdamW(model_finetune.parameters(), lr=lr, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=start_factor,\n",
        "    total_iters=warmup_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269f6509",
      "metadata": {
        "collapsed": true,
        "id": "269f6509"
      },
      "outputs": [],
      "source": [
        "train_finetune_model(model_finetune, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0229cdc8",
      "metadata": {
        "id": "0229cdc8"
      },
      "source": [
        "Пробуем инициализироваться предобученной моделью, только backbone:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a77b8b1",
      "metadata": {
        "id": "3a77b8b1"
      },
      "outputs": [],
      "source": [
        "model_pretrain = torch.load('./pretrain.pt', weights_only=False)\n",
        "model_finetune = FinetuneModel(model_pretrain.backbone, embedding_dim).to(device)\n",
        "optimizer = optim.AdamW(model_finetune.parameters(), lr=lr, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=start_factor,\n",
        "    total_iters=warmup_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79b3af9",
      "metadata": {
        "collapsed": true,
        "id": "c79b3af9"
      },
      "outputs": [],
      "source": [
        "train_finetune_model(model_finetune, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d7521a",
      "metadata": {
        "id": "60d7521a"
      },
      "source": [
        "Попробуем еще дополнительно иницилизировать user_context_fusion и candidate_projector:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d2cf28",
      "metadata": {
        "id": "28d2cf28"
      },
      "outputs": [],
      "source": [
        "model_pretrain = torch.load('./pretrain.pt', weights_only=False)\n",
        "model_finetune = FinetuneModel(model_pretrain.backbone, embedding_dim).to(device)\n",
        "model_finetune.user_context_fusion = model_pretrain.user_context_fusion\n",
        "model_finetune.candidate_projector = model_pretrain.candidate_projector\n",
        "\n",
        "optimizer = optim.AdamW(model_finetune.parameters(), lr=lr, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=start_factor,\n",
        "    total_iters=warmup_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9ae51d",
      "metadata": {
        "collapsed": true,
        "id": "0c9ae51d"
      },
      "outputs": [],
      "source": [
        "train_finetune_model(model_finetune, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58b7aa5",
      "metadata": {
        "id": "f58b7aa5"
      },
      "outputs": [],
      "source": [
        "def best_metrics_finetune_model(valid_loader):\n",
        "    valid_logits = []\n",
        "    valid_targets = []\n",
        "    with torch.inference_mode():\n",
        "        test_model = torch.load('./finetune.pt', weights_only=False)\n",
        "        for batch in tqdm(valid_loader):\n",
        "            batch = move_to_device(batch, device)\n",
        "            output = test_model(batch)\n",
        "            logits = output['logits']\n",
        "            targets = batch['candidates']['action_type']\n",
        "            lengths = batch['candidates']['lengths']\n",
        "            i = 0\n",
        "            for length in lengths:\n",
        "                if length > 1:\n",
        "                    valid_logits.append(logits[i:i + length].cpu().numpy())\n",
        "                    valid_targets.append(targets[i:i + length].cpu().numpy())\n",
        "                i += length\n",
        "\n",
        "    avg_valid_ndcg = 0\n",
        "    for logits, targets in zip(valid_logits, valid_targets):\n",
        "        avg_valid_ndcg += ndcg_score(targets[None,], logits[None,], k=10, ignore_ties=True)\n",
        "    avg_valid_ndcg /= len(valid_logits)\n",
        "    print(avg_valid_ndcg)\n",
        "\n",
        "test_finetune_model(valid_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}